{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DataWithAaditya/Max-Life-Health-Insurance-Cross-Sell-Prediction/blob/main/Max_Life_Health_Insurance_Cross_Sell_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Max Life Health Insurance Cross Sell Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Classification\n",
        "\n",
        "##### **Contribution**    - Individual"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zmmz272yU0rI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pvuJyHuAU0Uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project aims to predict whether a customer will purchase health insurance alongside their existing vehicle insurance. By analyzing customer demographics, vehicle details, and insurance history, we provide data-driven insights to help the business target potential buyers more effectively. We started with Exploratory Data Analysis (EDA) to identify missing values, outliers, and key patterns in the dataset. Through Univariate, Bivariate, and Multivariate Analysis, we gained a deeper understanding of feature distributions and relationships.\n",
        "\n",
        "Next, we focused on Data Preprocessing and Feature Engineering, where we handled missing values, treated outliers, encoded categorical variables, and scaled numerical features. We also created new meaningful features to enhance model performance. To validate our findings, we performed Hypothesis Testing, ensuring that key business assumptions were statistically significant before proceeding with model training.\n",
        "\n",
        "In the Model Building and Evaluation phase, we experimented with multiple machine learning models, including Logistic Regression, Random Forest, and XGBoost. We evaluated them using performance metrics such as accuracy, precision, recall, and F1-score, followed by hyperparameter tuning to optimize results. Finally, we provided actionable insights based on our findings, helping the business improve its marketing strategy, reduce acquisition costs, and increase conversion rates. This project demonstrates a complete end-to-end machine learning workflow, showcasing practical skills in data analysis, feature engineering, and predictive modeling, with a strong focus on business impact."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GitHub Link: [GitHub Link click here!](https://github.com/DataWithAaditya/Max-Life-Health-Insurance-Cross-Sell-Prediction/tree/main)"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insurance companies face challenges in identifying the right customers for additional policy sales. Many marketing efforts are wasted on customers who are not interested, while potential buyers are sometimes overlooked. Max Life Insurance wants to improve its cross-selling strategy by predicting which existing customers are likely to purchase health insurance. By leveraging machine learning, we can analyze customer data, such as demographics, vehicle history, and past insurance purchases, to build a predictive model that helps the company focus its marketing efforts on the right audience. The goal is to improve sales efficiency, reduce costs, and enhance customer satisfaction by offering relevant products to the right customers at the right time."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount drive if, working on Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Max Life Health Insurance Cross Sell Prediction/TRAIN-HEALTH INSURANCE CROSS SELL PREDICTION.csv')"
      ],
      "metadata": {
        "id": "7mT-Vgxmu-sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(\"Dataset Size\")\n",
        "print(\"Rows: \", df.shape[0])\n",
        "print(\"Columns: \", df.shape[1])"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "duplicate_values = df.duplicated().sum()\n",
        "duplicate_values"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "missing_values = df.isnull().sum()\n",
        "missing_values"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing missing values using a bar plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "missing_values.plot(kind=\"bar\", color=\"skyblue\")\n",
        "plt.title(\"Missing Values in Each Column\")\n",
        "plt.xlabel(\"Columns\")\n",
        "plt.ylabel(\"Count of Missing Values\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This confirms that there are no missing values in the dataset."
      ],
      "metadata": {
        "id": "LMh7hCw4zUUE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After loading the dataset and performing initial checks, I learned the following:\n",
        "\n",
        "- The dataset contains 381,109 rows and 12 columns.\n",
        "- It includes numerical and categorical features related to customers, their insurance history, and vehicle details.\n",
        "- The dataset has no missing values, which means it's complete and doesn’t require imputation.\n",
        "- Data types are appropriate for analysis, with numerical and categorical values correctly assigned.\n",
        "- There are no duplicate records, ensuring data integrity.\n",
        "\n",
        "The dataset is clean and well-structured, with no missing or duplicate values. It provides valuable information to predict which customers are likely to purchase health insurance. Next, we can explore feature distributions, outliers, and relationships between variables."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "print(\"Dataset Columns:\\n\", df.columns)"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset has 381,109 records with 12 features, including customer details, past insurance history, and vehicle-related information. Key features include:\n",
        "\n",
        "- Gender: Male or Female\n",
        "- Age: Customer's age in years\n",
        "- Driving_License: If the customer has a driving license (1 = Yes, 0 = No)\n",
        "- Region_Code: Location of the customer\n",
        "- Previously_Insured: If the customer already has an insurance policy (1 = Yes, 0 = No)\n",
        "- Vehicle_Age: How old the vehicle is (<1 Year, 1-2 Years, >2 Years)\n",
        "- Vehicle_Damage: If the vehicle was damaged before (Yes/No)\n",
        "- Annual_Premium: Insurance cost paid by the customer\n",
        "- Policy_Sales_Channel: How the policy was sold\n",
        "- Vintage: How long the customer has been with the company\n",
        "- Response (Target Variable): If the customer is interested in buying health insurance (1 = Yes, 0 = No)"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "unique_values = df.nunique()\n",
        "unique_values"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Detect Outliers"
      ],
      "metadata": {
        "id": "iG3RtJ5y4Wjz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select only numerical columns\n",
        "num_cols = df.select_dtypes(include=np.number).columns\n",
        "\n",
        "# Function to visualize outliers using Boxplots\n",
        "def plot_boxplots(data, columns):\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    for i, col in enumerate(columns, 1):\n",
        "        plt.subplot((len(columns) // 4) + 1, 4, i)  # Adjust layout dynamically\n",
        "        sns.boxplot(y=data[col], color='skyblue')\n",
        "        plt.title(f'Boxplot of {col}')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Call the function to plot boxplots\n",
        "plot_boxplots(df, num_cols)"
      ],
      "metadata": {
        "id": "U2vKmfmX4gS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Detecting outliers using IQR method\n",
        "def detect_outliers_iqr(data, column):\n",
        "    Q1 = data[column].quantile(0.25)  # First quartile (25th percentile)\n",
        "    Q3 = data[column].quantile(0.75)  # Third quartile (75th percentile)\n",
        "    IQR = Q3 - Q1  # Interquartile range\n",
        "\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
        "\n",
        "    print(f\"{column}: {len(outliers)} outliers detected\")\n",
        "    return outliers\n",
        "\n",
        "# Define numerical_features\n",
        "numerical_features = df.select_dtypes(include=np.number).columns\n",
        "\n",
        "# Check for outliers in all numerical features\n",
        "outlier_counts = {}\n",
        "for col in numerical_features:\n",
        "    outliers = detect_outliers_iqr(df, col)\n",
        "    outlier_counts[col] = len(outliers)\n",
        "\n",
        "# Display outlier summary\n",
        "print(\"\\nOutlier Summary:\")\n",
        "print(outlier_counts)"
      ],
      "metadata": {
        "id": "N38n5iOg5cf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write ready code for data analysis\n",
        "\n",
        "# Handling Outliers for Annual_Premium using Winsorization (Capping)\n",
        "def cap_outliers(data, column):\n",
        "    Q1 = data[column].quantile(0.25)  # 25th percentile\n",
        "    Q3 = data[column].quantile(0.75)  # 75th percentile\n",
        "    IQR = Q3 - Q1  # Interquartile range\n",
        "\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Capping outliers\n",
        "    data[column] = np.where(data[column] < lower_bound, lower_bound, data[column])\n",
        "    data[column] = np.where(data[column] > upper_bound, upper_bound, data[column])\n",
        "\n",
        "    print(f\"Outliers in {column} capped between {lower_bound:.2f} and {upper_bound:.2f}\")\n",
        "\n",
        "# Apply capping to 'Annual_Premium'\n",
        "cap_outliers(df, 'Annual_Premium')\n",
        "\n",
        "# Print duplicate values\n",
        "print(\"Duplicate Values: \", duplicate_values)\n",
        "\n",
        "# Print missing values\n",
        "print(\"Missing Values:\\n \", missing_values)\n",
        "\n",
        "# Unique values\n",
        "print(\"Unique Values Each Columns:\\n \", unique_values)\n",
        "\n",
        "# Data size after handling outliers\n",
        "print(\"Data Size\")\n",
        "print(\"Rows\", df.shape[0])\n",
        "print(\"Columns\", df.shape[1])"
      ],
      "metadata": {
        "id": "CR5Par6tFBW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After handling outliers\n",
        "\n",
        "# Detecting outliers using IQR method\n",
        "def detect_outliers_iqr(data, column):\n",
        "    Q1 = data[column].quantile(0.25)  # First quartile (25th percentile)\n",
        "    Q3 = data[column].quantile(0.75)  # Third quartile (75th percentile)\n",
        "    IQR = Q3 - Q1  # Interquartile range\n",
        "\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
        "\n",
        "    print(f\"{column}: {len(outliers)} outliers detected\")\n",
        "    return outliers\n",
        "\n",
        "# Define numerical_features\n",
        "numerical_features = df.select_dtypes(include=np.number).columns\n",
        "\n",
        "# Check for outliers in all numerical features\n",
        "outlier_counts = {}\n",
        "for col in numerical_features:\n",
        "    outliers = detect_outliers_iqr(df, col)\n",
        "    outlier_counts[col] = len(outliers)\n",
        "\n",
        "# Display outlier summary\n",
        "print(\"\\nOutlier Summary:\")\n",
        "print(outlier_counts)"
      ],
      "metadata": {
        "id": "-y-M9R86P583"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We performed several preprocessing steps to clean and prepare the data:\n",
        "\n",
        "1. Handling Missing Values & Duplicates\n",
        "\n",
        "- What we did:\n",
        "\n",
        "  - Checked for missing values in each column.\n",
        "  - Checked for duplicate values in each column.\n",
        "\n",
        "- Why we did it:\n",
        "\n",
        "  - Missing values can cause bias or errors in model predictions.\n",
        "  - Removing duplicates ensures that each data point is unique.\n",
        "\n",
        "2. Detecting & Handling Outliers\n",
        "\n",
        "- What we did:\n",
        "\n",
        "  - Used the Interquartile Range (IQR) Method to detect extreme values.\n",
        "  - Found outliers in three columns:\n",
        "    - Driving_License (812 outliers)\n",
        "    - Annual_Premium (10,320 outliers)\n",
        "    - Response (46,710 outliers)\n",
        "  - Applied capping (Winsorization) on Annual_Premium to limit extreme values.\n",
        "  - Left Driving_License and Response unchanged, as they are categorical (binary 0/1).\n",
        "\n",
        "- Why we did it:\n",
        "\n",
        "  - Outliers in numerical data can distort the model's learning process.\n",
        "  - Capping ensures extreme values don’t mislead the predictions.\n",
        "\n",
        "\n",
        "**Insights Gained:**\n",
        "- Missing Values Analysis:\n",
        "  - Most columns had no missing values, indicating a well-maintained dataset.\n",
        "\n",
        "- Duplicate Data:\n",
        "  - We checked and removed duplicate records to ensure better model performance.\n",
        "\n",
        "- Outlier Analysis:\n",
        "  - Annual_Premium had extreme values, meaning some customers were paying very high premiums compared to others.\n",
        "  - Insight: There might be a difference in premium rates based on customer segments.\n",
        "- Driving_License & Response were categorical, and outliers weren’t an issue there."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1: Distribution of Gender"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set figure size\n",
        "plt.figure(figsize=(6, 4))\n",
        "\n",
        "# Count plot for gender\n",
        "sns.countplot(x=df['Gender'], palette='coolwarm')\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Distribution of Gender', fontsize=14)\n",
        "plt.xlabel('Gender', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "\n",
        "# Display the chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** A count plot will help us understand the distribution of male and female customers. This is crucial because gender-based preferences may impact insurance purchase behavior."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- If the distribution is imbalanced, it may indicate that one gender is more likely to purchase health insurance than the other.\n",
        "- If there is a significant gender gap, we might need targeted marketing strategies for the underrepresented group."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- Positive Impact: If we find that one gender dominates, we can tailor promotional campaigns to the other gender to improve cross-selling.\n",
        "\n",
        "- Negative Impact: If gender imbalance exists and isn't addressed, we may miss out on potential customers."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2: Distribution of Age"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set figure size\n",
        "plt.figure(figsize=(6, 4))\n",
        "\n",
        "# Histogram for Age\n",
        "sns.histplot(df['Age'], bins=30, kde=True, color='royalblue')\n",
        "\n",
        "# Add titles and labels\n",
        "plt.title('Distribution of Age', fontsize=12)\n",
        "plt.xlabel('Age', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "\n",
        "# Display the chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** A histogram will show the age distribution of customers. This helps us identify which age groups are most common in the dataset."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- If most customers fall within a certain age range, it indicates that the company has a specific target audience for health insurance.\n",
        "\n",
        "- If we see two peaks (bimodal distribution), it may mean that there are two major customer segments."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- Positive Impact: If a certain age group dominates, marketing campaigns can be optimized to target them more effectively.\n",
        "- Negative Impact: If some age groups are missing, it may indicate that Max Life Insurance is not reaching younger or older potential customers."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3: Distribution of Region_code"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the figure size\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Bar plot for Region_code\n",
        "sns.countplot(x=df['Region_Code'], palette='viridis', order=df['Region_Code'].value_counts().index)\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Customer Distribution by Region', fontsize=12)\n",
        "plt.xlabel('Region Code', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "plt.xticks(rotation=45) #Rotate labels for better readability\n",
        "\n",
        "# Display the chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** A bar chart will help visualize the number of customers from different regions. This is important because customer behavior may vary by region, affecting sales and marketing strategies."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- If certain regions dominate, it indicates that Max Life Insurance has a strong presence in specific locations.\n",
        "- If some regions have low customer counts, it may signal untapped market potential.\n"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- Positive Impact: If the company knows which regions have high engagement, it can focus resources there for better customer retention.\n",
        "- Negative Impact: If some regions are underrepresented, the company may be missing out on potential customers, signaling the need for region-specific marketing efforts."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4: Distribution of Driving_License"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set figure size\n",
        "plt.figure(figsize=(6, 4))\n",
        "\n",
        "# Count plot for Driving_License\n",
        "sns.countplot(x=df['Driving_License'], palette='pastel')\n",
        "\n",
        "# Add the title and labels\n",
        "plt.title('Distribution of Driving License Holder', fontsize=14)\n",
        "plt.xlabel('Driving License Holder', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "\n",
        "# Display the chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** A count plot will help us understand how many customers possess a driving license. Although this feature may seem unrelated to health insurance, it could correlate with customer lifestyle and risk assessment."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- If most customers have a driving license (1), it suggests that they are mobile and possibly more independent in decision-making.\n",
        "- If there is a balanced split between license holders and non-holders, it indicates that driving status might not be a major factor in insurance sales."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- Positive Impact: If driving license holders show higher conversion rates, Max Life Insurance can target vehicle owners for cross-selling opportunities.\n",
        "- Negative Impact: If non-license holders are underrepresented, the company might miss out on a key customer base (e.g., those who prefer public transport)."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5: Distribution of Previously_Insured"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set figure size\n",
        "plt.figure(figsize=(6, 4))\n",
        "\n",
        "# Count plot for Previously_Insured\n",
        "sns.countplot(x=df['Previously_Insured'], palette='Set2')\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Distribution of Previously Insured Customer', fontsize=14)\n",
        "plt.xlabel('Previously Insured (0 = No, 1 = Yes)', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "plt.legend(labels=[\"No\", \"Yes\"])\n",
        "\n",
        "# Display the chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** A count plot will show how many customers already have an insurance policy. This is crucial because customers who don’t have existing insurance are potential targets for cross-selling."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- If most customers have 0 (No previous insurance), it means a large untapped market exists for Max Life Insurance.\n",
        "- If many customers have 1 (Already insured), the company may need to focus more on competitive pricing and benefits to attract switchers."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- Positive Impact: If a significant number of customers don’t have prior insurance, the company can easily convert them with the right marketing strategy.\n",
        "- Negative Impact: If most customers are already insured, then cross-selling will be difficult, and the company may need to differentiate its offerings to attract them."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6: Distribution of Vehicle_Age"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set figure size\n",
        "plt.figure(figsize=(6, 4))\n",
        "\n",
        "# Count plot for Vehicle_Age\n",
        "sns.countplot(x=df['Vehicle_Age'], palette='coolwarm')\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Distribution of Vehicle Age', fontsize=14)\n",
        "plt.xlabel('Vehicle Age', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "\n",
        "# Display the chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** A bar chart will help visualize how many customers own new vs. old vehicles. Vehicle age can influence insurance needs and risk assessment."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- If most vehicles are < 1 year old, it suggests that Max Life Insurance can focus on first-time insurance buyers.\n",
        "- If most vehicles are > 2 years old, then customers may be looking for better renewal offers instead of new insurance."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- Positive Impact: If many customers have older vehicles, Max Life Insurance can offer renewal discounts and loyalty benefits.\n",
        "- Negative Impact: If only new vehicle owners are interested, the company may struggle to retain long-term customers."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7: Distribution of Vehicle_Damage"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set figure size\n",
        "plt.figure(figsize=(6, 4))\n",
        "\n",
        "# Count plot for Vehicle_Damage\n",
        "sns.countplot(x=df['Vehicle_Damage'], palette='magma')\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Distribution of Vehicle Damage History', fontsize=14)\n",
        "plt.xlabel('Vehicle Damage (Yes = 1, No = 0)', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "\n",
        "# Display the chart\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** A count plot will help us see how many customers have previously damaged their vehicles. Customers who experienced damage before might be more likely to buy insurance.\n",
        "\n"
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- If many customers have experienced vehicle damage (1), they may be more interested in purchasing insurance.\n",
        "- If most customers have not experienced damage (0), it suggests they might be less aware of insurance benefits."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- Positive Impact: If a significant number of customers have experienced damage before, they are high-potential leads for cross-selling insurance.\n",
        "- Negative Impact: If most customers have never faced damage, the company may need educational marketing campaigns to raise awareness about insurance importance.\n",
        "\n"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8: Distribution of Annual_Premium"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set figure size\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "# Histogram for Annual_Premium\n",
        "sns.histplot(df['Annual_Premium'], bins=50, kde=True, color='blue')\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Distribution of Annual Premium Amounts', fontsize=14)\n",
        "plt.xlabel('Annual Premium', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "\n",
        "# Display the chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** A histogram is best for visualizing the spread of annual premium amounts paid by customers. This helps in identifying common premium ranges and potential pricing strateg"
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- If the distribution is right-skewed, it suggests that most customers are paying lower premiums, while a few are paying high amounts.\n",
        "- If there is a clear peak, it indicates a common premium range, which can help in setting competitive pricing strategies."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- Positive Impact: If a specific premium range dominates, Max Life Insurance can offer tailored plans to attract more customers.\n",
        "- Negative Impact: If too many customers pay very low premiums, profitability may be affected, requiring better pricing models."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9: Distribution of Policy_Sales_Channel"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set figure size\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Get the top 15 most used sales channels\n",
        "top_channels = df['Policy_Sales_Channel'].value_counts().head(20)\n",
        "\n",
        "# Horizontal bar plot\n",
        "sns.barplot(x=top_channels.values, y=top_channels.index, palette='viridis')\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Top 15 Policy Sales Channels', fontsize=14)\n",
        "plt.xlabel('Number of Policies Sold', fontsize=12)\n",
        "plt.ylabel('Sales Channel', fontsize=12)\n",
        "plt.xticks(rotation=45) #Rotate labels for better readability\n",
        "\n",
        "# Display the chart\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** A bar chart will make it easier to read, focusing on the top-performing channels rather than all channels."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- The top-performing sales channels contribute the most to policy sales.\n",
        "- If certain high-ranking channels are identified, more investment can be directed toward them.\n",
        "- Lower-performing channels in the top 15 might need optimization instead of removal."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- Positive Impact: Max Life Insurance can focus on high-performing channels to increase sales efficiency.\n",
        "- Negative Impact: If few channels dominate, the company might rely too much on them, creating a risk if those channels decline in the future."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10: Age vs. Response (Insurance Purchase Decision by Age Group)"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set figure size\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "# Boxplot for Age vs. Response\n",
        "sns.boxplot(x=df['Response'], y=df['Age'], palette='coolwarm')\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Age Distribution by Response', fontsize=14)\n",
        "plt.xlabel('Response (0 = No, 1 = Yes)', fontsize=12)\n",
        "plt.ylabel('Age', fontsize=12)\n",
        "\n",
        "# Display the chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** A boxplot will help us see how age is distributed for customers who purchased insurance (Response = 1) vs. those who didn’t (Response = 0). This will reveal which age groups are more likely to buy insurance."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- If older customers (above 40) are more likely to buy insurance, marketing should target them with better retirement and health security plans.\n",
        "- If younger customers (below 30) are hesitant to buy, Max Life Insurance should offer more attractive discounts and flexible premium options to encourage sign-ups."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- Positive Impact: Understanding which age group is more likely to purchase helps in designing personalized campaigns.\n",
        "- Negative Impact: If younger customers are not interested, the company might be missing out on a long-term customer base."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11: Annual Premium vs. Response (Insurance Purchase Decision by Premium Amount)"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set fugure size\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "# Boxplot for Annual Premium vs. Response\n",
        "sns.boxplot(x=df['Response'], y=df['Annual_Premium'], palette='magma')\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Annual Premium Distribution by Response', fontsize=14)\n",
        "plt.xlabel('Response (0 = No, 1 = Yes)', fontsize=12)\n",
        "plt.ylabel('Annual Premium', fontsize=12)\n",
        "\n",
        "# Display the chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** A boxplot will help us see if there is a significant difference in the Annual Premium for customers who purchased insurance (Response = 1) vs. those who didn’t (Response = 0)."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- If customers who bought insurance (Response = 1) tend to have higher premiums, it means higher-priced policies are more appealing, and the company should focus on selling premium plans.\n",
        "- If customers who didn’t buy (Response = 0) have lower premiums, Max Life Insurance may need to re-evaluate its low-cost plans to make them more attractive."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- Positive Impact: Understanding the preferred premium range helps in customizing policy pricing for better sales.\n",
        "- Negative Impact: If lower-premium plans are being ignored, the company might be losing a large customer base that prefers affordability."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12: Vehicle Age vs. Response (Insurance Purchase Decision by Vehicle Age)"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set figure size\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "# Count plot for Vehicle Age vs. Response\n",
        "sns.countplot(x=df['Vehicle_Age'], hue=df['Response'], palette='viridis')\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Insurance Purchase Decision by Vehicle Age', fontsize=14)\n",
        "plt.xlabel('Vehicle Age', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "plt.legend(title=\"Response\", labels=[\"Not Purchased (0)\", \"Purchased (1)\"])\n",
        "\n",
        "# Display the chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** A bar chart will help us compare how many customers from different Vehicle Age groups decided to purchase insurance (Response = 1) vs. those who didn’t (Response = 0)."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- If older vehicles (>2 Years) have a higher Response = 1 rate, it suggests that owners of older vehicles are more concerned about insurance coverage.\n",
        "- If newer vehicles (<1 Year) show a lower Response = 1 rate, it might indicate that owners of new cars rely more on manufacturer-provided insurance."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- Positive Impact: Understanding which vehicle age group is more likely to purchase insurance helps in targeted marketing strategies.\n",
        "- Negative Impact: If owners of new vehicles are less likely to buy insurance, the company should offer special discounts or added benefits to attract them."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13: Vehicle Damage vs. Response (Impact of Previous Damage on Insurance Purchase)"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set figure size\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "# Count plot for Vehicle Damage vs. Response\n",
        "sns.countplot(x=df['Vehicle_Damage'], hue=df['Response'], palette='coolwarm')\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Impact of Vehicle Damage on Insurance Purchase', fontsize=14)\n",
        "plt.xlabel('Vehicle Damage History', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "plt.legend(title=\"Response\", labels=[\"Not Purchased (0)\", \"Purchased (1)\"])\n",
        "\n",
        "# Display the chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** A bar chart will help visualize whether customers whose vehicles were previously damaged (Vehicle_Damage = Yes) are more likely to purchase insurance compared to those whose vehicles were not damaged (Vehicle_Damage = No)."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- If customers whose vehicles were previously damaged (Vehicle_Damage = Yes) are more likely to buy insurance, it indicates that past accidents increase interest in protection.\n",
        "- If customers with no vehicle damage (Vehicle_Damage = No) rarely buy insurance, it suggests they might not see the need for it."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- Positive Impact: If past damage increases insurance purchases, the company can target accident-prone customers with special offers.\n",
        "- Negative Impact: If customers with no previous damage don’t buy insurance, the company should educate them on unexpected risks to increase sales."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14: egion Code vs. Response (Impact of Region on Insurance Purchase)"
      ],
      "metadata": {
        "id": "WRAePFvUM2Cs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set figure size\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Count plot for Region Code vs. Response\n",
        "sns.countplot(x=df['Region_Code'], hue=df['Response'], palette='Spectral')\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Insurance Purchase Decision by Region Code', fontsize=14)\n",
        "plt.xlabel('Region Code', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "plt.legend(title=\"Response\", labels=[\"Not Purchased (0)\", \"Purchased (1)\"])\n",
        "\n",
        "# Display the chart\n",
        "plt.xticks(rotation=90)  # Rotate labels if needed\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AamorCU1NA-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "O1bb7DAQNQuk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ansewr:** A bar chart will help us visualize whether certain regions have a higher or lower response rate when it comes to purchasing insurance. This can help identify high-potential regions for marketing efforts."
      ],
      "metadata": {
        "id": "4awOHdUgNTM8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "VmOL_rjwNe5k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- If certain regions have a much higher percentage of insurance buyers (Response = 1), the company should focus marketing campaigns on these regions.\n",
        "- If some regions have very low insurance adoption, it might indicate a lack of awareness or affordability issues."
      ],
      "metadata": {
        "id": "xafkPNN1NhJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "DCHiRWeyNtk-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- Positive Impact: Identifying high-performing regions allows Max Life Insurance to allocate resources efficiently and focus marketing in high-response areas.\n",
        "-  Negative Impact: If some regions are underperforming, the company needs to research why (e.g., economic conditions, lack of awareness, alternative insurance providers)."
      ],
      "metadata": {
        "id": "bC-Tt59HNzOX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15:Previously Insured vs. Response (Impact of Existing Insurance on New Purchase)"
      ],
      "metadata": {
        "id": "A5g7__myOFSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the figure size\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "# Count plot for Previously Insured vs. Response\n",
        "sns.countplot(x=df['Previously_Insured'], hue=df['Response'], palette='pastel')\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Impact of Existing Insurance on New Purchase', fontsize=14)\n",
        "plt.xlabel('Previously Insured (0 = No, 1 = Yes)', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "plt.legend(title=\"Response\", labels=[\"Not Purchased (0)\", \"Purchased (1)\"])\n",
        "\n",
        "# Display the chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-6V9a9KqOK1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "OAArihWiOY9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** A bar chart will help us visualize whether customers who are already insured (Previously_Insured = 1) are more or less likely to buy additional health insurance compared to those who do not have existing insurance (Previously_Insured = 0)."
      ],
      "metadata": {
        "id": "k0C_H8IpObwj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ozGyFbUfOj4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ansewr:**\n",
        "- If customers who are previously insured (Previously_Insured = 1) rarely buy additional insurance (Response = 0), it suggests that once insured, customers don’t see the need for another policy.\n",
        "- If customers without prior insurance (Previously_Insured = 0) have a high insurance purchase rate (Response = 1), it indicates that the company is attracting first-time insurance buyers."
      ],
      "metadata": {
        "id": "T54Tr9sxOoWT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Chart - 16: Impact of Annual Premium & Age on Insurance Purchase"
      ],
      "metadata": {
        "id": "_q4usrPGPkrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set figure size\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Scatter plot for Age vs. Annual Premium, colored by Response\n",
        "sns.scatterplot(x=df['Age'], y=df['Annual_Premium'], hue=df['Response'], alpha=0.6, palette='coolwarm')\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Age vs. Annual Premium (Colored by Insurance Purchase Response)', fontsize=14)\n",
        "plt.xlabel('Age', fontsize=12)\n",
        "plt.ylabel('Annual Premium', fontsize=12)\n",
        "plt.legend(title=\"Response\", labels=[\"Not Purchased (0)\", \"Purchased (1)\"])\n",
        "\n",
        "# Display the chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZwvlegmKPu8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "lKOGeKE0QFSR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** A scatter plot with color-coded responses will help us analyze how Annual Premium and Age together influence the insurance purchase decision."
      ],
      "metadata": {
        "id": "vMeBb1_LQH3r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "Ma40tZ-5QVDM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- If younger people (Age < 30) are paying lower premiums but still buying insurance, it suggests they prefer affordability.\n",
        "- If older people (Age > 50) are paying high premiums but not purchasing insurance, the company might need better incentives for this group.\n",
        "- If there’s a cluster where people are paying high premiums and purchasing insurance, that’s a target segment for premium policy sales."
      ],
      "metadata": {
        "id": "AEnxx0EeQXdT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "8ptxYVbXQrd5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- Positive Impact: If a certain age group is responding well, the company can focus on targeting that segment with personalized offers.\n",
        "- Negative Impact: If high-premium customers aren’t buying insurance, the company should analyze pricing strategies or provide better value-added services."
      ],
      "metadata": {
        "id": "7e4FOuxSQutk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Chart 17: Vehicle Age vs. Vehicle Damage vs. Response"
      ],
      "metadata": {
        "id": "PJSlNsVQRCXy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set figure size\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create a stacked bar plot for Vehicle Age & Vehicle Damage vs. Response\n",
        "sns.histplot(data=df, x=\"Vehicle_Age\", hue=\"Vehicle_Damage\", multiple=\"stack\", palette=\"coolwarm\")\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Impact of Vehicle Age & Damage on Insurance Purchase', fontsize=14)\n",
        "plt.xlabel('Vehicle Age', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "plt.legend(title=\"Vehicle Damage\", labels=[\"No Damage\", \"Damaged\"])\n",
        "\n",
        "# Display the chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OIkFKpg6RH9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "4bM9ONGaRTUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** A stacked bar chart will help us visualize how Vehicle Age and Vehicle Damage together influence insurance purchases."
      ],
      "metadata": {
        "id": "kWu0dWF3RW-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "He6UIozFRlK6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- If customers with older vehicles and past damage have a higher insurance purchase rate (Response = 1), it suggests they are more risk-aware and likely to buy insurance.\n",
        "- If customers with newer vehicles and no past damage are not purchasing insurance, they may not see the need for coverage."
      ],
      "metadata": {
        "id": "5A8rUgZJRnCD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "__cznBpcRx-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- Positive Impact: If owners of older and damaged vehicles are actively purchasing insurance, the company can target them with better renewal offers or add-on coverage plans.\n",
        "- Negative Impact: If new vehicle owners are ignoring insurance, the company should educate them on the benefits of early coverage."
      ],
      "metadata": {
        "id": "oDWivewHRz1R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Chart - 18: Policy Sales Channel vs. Response vs. Age Group"
      ],
      "metadata": {
        "id": "N6OGS3f7SQ3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set figure size\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Creating Age Groups\n",
        "df['Age_Group'] = pd.cut(df['Age'], bins=[20, 30, 40, 50, 60, 70], labels=['20-30', '30-40', '40-50', '50-60', '60-70'])\n",
        "\n",
        "# Plot the grouped bar chart\n",
        "sns.countplot(data=df, x='Policy_Sales_Channel', hue='Response', order=df['Policy_Sales_Channel'].value_counts().index[:10])\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Policy Sales Channel Performance Across Age Groups', fontsize=14)\n",
        "plt.xlabel('Policy Sales Channel', fontsize=12)\n",
        "plt.ylabel('Number of Customers', fontsize=12)\n",
        "plt.legend(title=\"Response\", labels=[\"Not Purchased (0)\", \"Purchased (1)\"])\n",
        "\n",
        "# Display the chart\n",
        "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mhY3H_j7SVYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "I1OoXbgpSeKS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** A grouped bar chart will help us analyze how different sales channels perform for different age groups in converting leads into customers."
      ],
      "metadata": {
        "id": "7ez8XUHxSipK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F3jkVu3lSmlp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- If a few sales channels have high conversion rates, the company should focus on scaling them up.\n",
        "- If some channels perform poorly in converting customers, they may need better training or incentives."
      ],
      "metadata": {
        "id": "S7Etemh9Soap"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "dHS9Y8YSS0OD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- Positive Impact: Focus more on the top-performing channels to increase sales.\n",
        "- Negative Impact: If many sales channels have low performance, it indicates a lack of efficiency in the sales strategy."
      ],
      "metadata": {
        "id": "ls_6Rj03S2NV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 19 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "\n",
        "# Create a copy of the dataframe to avoid modifying the original one\n",
        "df_encoded = df.copy()\n",
        "\n",
        "# Convert categorical columns to numerical\n",
        "df_encoded['Gender'] = df_encoded['Gender'].map({'Male': 0, 'Female': 1})  # Convert Male to 0, Female to 1\n",
        "df_encoded['Vehicle_Age'] = df_encoded['Vehicle_Age'].map({'< 1 Year': 0, '1-2 Year': 1, '> 2 Years': 2})  # Encode Vehicle Age\n",
        "df_encoded['Vehicle_Damage'] = df_encoded['Vehicle_Damage'].map({'No': 0, 'Yes': 1})  # Convert No to 0, Yes to 1\n",
        "\n",
        "# Drop non-numeric columns that may cause issues\n",
        "df_encoded = df_encoded.select_dtypes(include=['number'])\n",
        "\n",
        "# Plot the correlation heatmap\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(df_encoded.corr(), annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "\n",
        "# Add title\n",
        "plt.title('Correlation Heatmap of Key Features', fontsize=14)\n",
        "\n",
        "# Display the chart\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "A correlation heatmap helps us understand how different numerical variables are related. This can:\n",
        "\n",
        "- Highlight strong positive or negative correlations between features.\n",
        "- Help in feature selection by identifying redundant variables.\n",
        "- Provide insights on whether certain factors impact insurance purchase behavior."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- If Annual Premium is highly correlated with Age or Driving License, it may indicate pricing biases in the policy.\n",
        "- If Vehicle Age and Vehicle Damage have a strong correlation, it could suggest older vehicles are more prone to damage.\n",
        "- If Response (purchase decision) correlates with specific features, it helps in predictive modeling."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization\n",
        "\n",
        "# Selecting key numerical features for pairplot\n",
        "features = ['Age', 'Annual_Premium', 'Vintage', 'Vehicle_Damage', 'Response']\n",
        "\n",
        "# Create the pairplot with hue based on Response (1: Purchased, 0: Not Purchased)\n",
        "sns.pairplot(df_encoded[features], hue=\"Response\", palette=\"coolwarm\")\n",
        "\n",
        "# Display the chart\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "A pairplot (scatterplot matrix) helps us:\n",
        "\n",
        "- Visualize relationships between numerical variables.\n",
        "- Identify potential clusters or separations between customers who purchased vs. didn't purchase insurance.\n",
        "- Detect patterns and trends that influence cross-selling."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- If Vehicle Damage vs. Response shows separation, customers with prior vehicle damage are more likely to buy insurance.\n",
        "- If Age vs. Annual Premium forms clusters, different age groups may have distinct premium pricing trends.\n",
        "- If Vintage impacts Response, longer-tenured customers may have a higher purchase likelihood."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Now that we’ve observed the pairplot, we need to enhance feature representation to improve patterns for modeling. Let’s proceed."
      ],
      "metadata": {
        "id": "OLzAQ7ecqKVv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Feature Scaling & Transformation"
      ],
      "metadata": {
        "id": "UugcCrjSqWNp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some features like Annual_Premium have a wide range. This may affect model performance. We will:\n",
        "\n",
        "- Apply Log Transformation to reduce skewness.\n",
        "- Normalize features (Min-Max Scaling or Standardization)."
      ],
      "metadata": {
        "id": "VikJfO2SqqDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Log transformation on 'Annual_Premium' to reduce skewness\n",
        "df['Annual_Premium_Log'] = np.log1p(df['Annual_Premium'])\n",
        "\n",
        "# Standard Scaling for numerical features\n",
        "scaler = StandardScaler()\n",
        "scaled_features = ['Age', 'Annual_Premium_Log', 'Vintage']\n",
        "df[scaled_features] = scaler.fit_transform(df[scaled_features])\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "_tJtiykdqtFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Why?\n",
        "\n",
        "- Log transformation helps stabilize variance.\n",
        "- Standard Scaling ensures all features have similar importance."
      ],
      "metadata": {
        "id": "QAVGEZ2nq_BC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Categorical Columns\n",
        "categorical_cols = ['Gender', 'Vehicle_Age', 'Age_Group', 'Annual_Premium']\n",
        "\n",
        "# Apply Label Encoding\n",
        "le = LabelEncoder()\n",
        "for col in categorical_cols:\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Check if conversion is successful\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "KTbpYC2RsqOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2: Correlation Heatmap"
      ],
      "metadata": {
        "id": "rNp-yoYHtU7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert \"Yes/No\" to 1/0\n",
        "df.replace({'Yes': 1, 'No': 0}, inplace=True)"
      ],
      "metadata": {
        "id": "K_VDDx2auFop"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "categorical_cols = ['Gender', 'Vehicle_Age', 'Premium_Segment']  # Add relevant columns\n",
        "\n",
        "for col in categorical_cols:\n",
        "    if col in df.columns:\n",
        "        df[col] = le.fit_transform(df[col])"
      ],
      "metadata": {
        "id": "fripx3ikuVLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set figure size\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "# Heatmap for correlation\n",
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', linewidths=0.5)\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "\n",
        "# Display the chart\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qc7ZVZxttZMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- Null Hypothesis (H0): There is no significant difference in the Annual Premium between customers who showed interest in the health insurance policy (Response = 1) and those who did not (Response = 0).\n",
        "- Alternate Hypothesis (H1): There is a significant difference in the Annual Premium between customers who showed interest (Response = 1) and those who did not (Response = 0)."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Separate data into two groups\n",
        "group_0 = df[df['Response'] == 0]['Annual_Premium']\n",
        "group_1 = df[df['Response'] == 1]['Annual_Premium']\n",
        "\n",
        "# Perform independent t-test\n",
        "t_stat, p_value = ttest_ind(group_0, group_1, equal_var=False)\n",
        "\n",
        "# Print result\n",
        "print(f\"T-statistic: {t_stat:.4f}, P-value: {p_value:.4f}\")\n",
        "\n",
        "# Conclusion\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis (H₀): There is a significant difference in Annual Premium between responders and non-responders.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis (H₀): No significant difference in Annual Premium.\")\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** Statistical Test Used: Independent t-test"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- The independent t-test is used when we want to compare the means of two independent groups to check if there is a significant difference between them.\n",
        "- Here, we are comparing the Annual Premium values for two groups:\n",
        "  - Customers who showed interest (Response = 1)\n",
        "  - Customers who did not show interest (Response = 0)\n",
        "- Since Annual Premium is a continuous numerical variable, and we are comparing two independent groups, the t-test is the best choice."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- Null Hypothesis (H0): The distribution of vehicle age is the same for customers who purchased health insurance (Response = 1) and those who did not (Response = 0).\n",
        "- Alternate Hypothesis (H1): The distribution of vehicle age differs significantly between customers who purchased health insurance (Response = 1) and those who did not (Response = 0)."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "import scipy.stats as stats\n",
        "import pandas as pd\n",
        "\n",
        "# Create a contingency table\n",
        "contingency_table = pd.crosstab(df['Vehicle_Age'], df['Response'])\n",
        "\n",
        "# Perform Chi-Square test\n",
        "chi2_stat, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "\n",
        "# Print results\n",
        "print(f\"Chi-Square Statistic: {chi2_stat:.4f}, P-value: {p_value:.4f}\")\n",
        "\n",
        "# Conclusion\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis (H₀): Vehicle Age distribution differs significantly for responders and non-responders.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis (H₀): No significant difference in Vehicle Age distribution.\")\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** Statistical Test Used: Chi-Square Test for Independence"
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- The Chi-Square Test is used when we need to check if two categorical variables are dependent or independent.\n",
        "- Here, both Vehicle_Age and Response are categorical variables, making the Chi-Square Test the best choice to analyze their relationship."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- Null Hypothesis (H0): There is no significant correlation between Annual Premium and Age of the customers.\n",
        "-Alternate Hypothesis (H1): There is a significant correlation between Annual Premium and Age of the customers.\n"
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Perform Pearson correlation test\n",
        "corr_coef, p_value = pearsonr(df['Annual_Premium'], df['Age'])\n",
        "\n",
        "# Print results\n",
        "print(f\"Pearson Correlation Coefficient: {corr_coef:.4f}, P-value: {p_value:.4f}\")\n",
        "\n",
        "# Conclusion\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject the null hypothesis (H₀): There is a significant correlation between Age and Annual Premium.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis (H₀): No significant correlation between Age and Annual Premium.\")"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:** Statistical Test Used: Pearson Correlation Test"
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- The Pearson correlation test is used to measure the linear relationship between two continuous numerical variables.\n",
        "- Since Annual Premium and Age are both numerical, we use Pearson’s correlation test to check if there is a significant relationship between them."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "\n",
        "# Imputation Strategy\n",
        "for col in df.columns:\n",
        "    if df[col].isnull().sum() > 0:  # If missing values exist\n",
        "        if df[col].dtype == 'object':  # Categorical columns\n",
        "            df[col].fillna(df[col].mode()[0], inplace=True)  # Fill with mode\n",
        "        else:  # Numerical columns\n",
        "            df[col].fillna(df[col].median(), inplace=True)  # Fill with median\n",
        "\n",
        "print(\"\\nMissing values handled successfully!\")"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "To handle missing values in the dataset, we used the following techniques:\n",
        "1. For Numerical Columns: Median Imputation\n",
        "  - We replaced missing values in numerical columns with the median value of that column\n",
        "  - Why? The median is less affected by extreme values (outliers) compared to the mean, making it a more reliable choice when dealing with skewed data.\n",
        "2. For Categorical Columns: Mode Imputation\n",
        "  - We replaced missing values in categorical columns with the most frequent value (mode) in that column.\n",
        "  - Why? Categorical data represents categories like \"Male/Female\" or \"Yes/No,\" so filling missing values with the most common category helps maintain consistency in the data"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature selection helps in identifying the most relevant variables that influence the target outcome, improving model performance and reducing complexity."
      ],
      "metadata": {
        "id": "Kr6ufZ6V0L5x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####1. Removing Irrelevant Features"
      ],
      "metadata": {
        "id": "XMSvove80SSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping features that are not useful for prediction\n",
        "df.drop(['id'], axis=1, inplace=True)\n",
        "print(\"Irrelevant features removed.\")"
      ],
      "metadata": {
        "id": "OKZqei-V0WuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####2. Checking Feature Correlation"
      ],
      "metadata": {
        "id": "yeAfOXkB1K03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Compute correlation matrix\n",
        "corr_matrix = df.corr()\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "plt.title(\"Feature Correlation Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3dz0BtIa1R6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Drop one feature from any pair with correlation > 0.8."
      ],
      "metadata": {
        "id": "fmYJio882wRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop highly correlated and redundant features\n",
        "df.drop(columns=['Annual_Premium', 'Age_Group', 'Previously_Insured'], inplace=True)\n",
        "\n",
        "# Check the updated dataframe\n",
        "print(\"Updated Dataset Columns:\", df.columns)"
      ],
      "metadata": {
        "id": "7L_e9tSQ2yE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####3. Feature Importance Using Mutual Information"
      ],
      "metadata": {
        "id": "_isaPLEM3NQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import mutual_info_classif\n",
        "import pandas as pd\n",
        "\n",
        "# Define features and target\n",
        "X = df.drop(columns=['Response'])  # Assuming 'Response' is the target variable\n",
        "y = df['Response']\n",
        "\n",
        "# Compute mutual information scores\n",
        "mi_scores = mutual_info_classif(X, y, random_state=42)\n",
        "\n",
        "# Convert to DataFrame for visualization\n",
        "mi_scores_df = pd.DataFrame({'Feature': X.columns, 'MI Score': mi_scores})\n",
        "mi_scores_df = mi_scores_df.sort_values(by='MI Score', ascending=False)\n",
        "\n",
        "# Display scores\n",
        "print(\"Mutual Information Scores for Feature Selection:\")\n",
        "print(mi_scores_df)\n"
      ],
      "metadata": {
        "id": "ibOQY11G3SBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Drop features with very low MI scores (< 0.01)."
      ],
      "metadata": {
        "id": "wXGn00PH3nOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "low_mi_features = mi_scores_df[mi_scores_df['MI Score'] < 0.01]['Feature'].tolist()\n",
        "df.drop(columns=low_mi_features, inplace=True)\n",
        "print(\"Low-information features removed.\")\n"
      ],
      "metadata": {
        "id": "Sdb1G1Js3qna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####4. Using Recursive Feature Elimination (RFE)"
      ],
      "metadata": {
        "id": "KUI436RR3ycG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Initialize model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Apply RFE\n",
        "rfe = RFE(model, n_features_to_select=10)  # Keep top 10 features\n",
        "X_rfe = rfe.fit_transform(X, y)\n",
        "\n",
        "# Get selected features\n",
        "selected_features = X.columns[rfe.support_]\n",
        "print(\"Selected Features Using RFE:\", selected_features)\n"
      ],
      "metadata": {
        "id": "YP7YLjSz32eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "We used multiple feature selection techniques to keep only the most relevant features for our model:\n",
        "\n",
        "1. Correlation Analysis (Heatmap): Removed highly correlated features to avoid redundancy (e.g., dropped Annual_Premium in favor of Annual_Premium_Log).\n",
        "2. Domain Knowledge: Eliminated features that didn’t add predictive value (e.g., dropped Age_Group since it duplicated Age).\n",
        "3. Variance Threshold: Removed features with almost no variation, as they don’t contribute to predictions.\n",
        "4. Feature Importance (Random Forest): Ranked features based on their predictive power and dropped the least important ones."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "The most important features we identified for prediction are:\n",
        "\n",
        "1. Age: Directly impacts insurance buying behavior.\n",
        "2. Vehicle_Age: Older vehicles may have lower chances of cross-selling.\n",
        "3. Vehicle_Damage: A strong indicator of customer interest in additional insurance.\n",
        "4. Previously_Insured: Determines whether a customer already has coverage.\n",
        "5. Annual_Premium_Log: Represents the cost customers are paying, influencing their buying decision.\n",
        "6. Policy_Sales_Channel: Helps understand which sales channel is more effective.\n",
        "7. Response: The target variable indicating customer interest.\n",
        "\n",
        "These features provide strong signals about customer behavior, making them crucial for accurate predictions."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "print(\"I has been dropped redundent feature during feature selection, we don’t need to transform it.\")\n"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Identify numerical columns (excluding categorical ones)\n",
        "num_cols = ['Age']  # Add more if necessary\n",
        "\n",
        "# Initialize StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit and transform the numerical columns\n",
        "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
        "\n",
        "print(\"Feature Scaling Completed Successfully!\")"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?\n",
        "\n",
        "- I used Standardization (StandardScaler) to scale the data because it ensures all numerical features have a mean of 0 and a standard deviation of 1. This helps improve the performance of machine learning models, especially those that rely on distance-based calculations (like logistic regression and SVM). Standardization is ideal when the data follows a normal distribution or has outliers, as it prevents features with larger values from dominating the model"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "I used an 80-20 split (80% for training and 20% for testing).\n",
        "\n",
        "Why?\n",
        "- 80% Training Data: Helps the model learn better patterns.\n",
        "- 20% Testing Data: Ensures a fair evaluation of the model's performance.\n",
        "- Stratified Sampling: Maintains the same class distribution in both train & test sets, which is important for imbalanced datasets like ours.\n",
        "\n",
        "This balance prevents overfitting and ensures the model generalizes well to unseen data."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- Yes, the dataset is imbalanced because the majority class (0) has a much higher count than the minority class (1).\n",
        "\n",
        "- From the bar chart, the \"Response\" variable shows that most customers did not respond (0), while only a small portion responded (1).\n",
        "\n",
        "- This imbalance can cause the model to favor the majority class, leading to poor predictions for the minority class. That's why handling the imbalance is necessary to improve model performance."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count the occurrences of each class in 'Response'\n",
        "class_counts = df['Response'].value_counts()\n",
        "\n",
        "# Plot class distribution\n",
        "plt.figure(figsize=(4, 4))\n",
        "sns.barplot(x=class_counts.index, y=class_counts.values, palette=\"viridis\")\n",
        "plt.xlabel(\"Response (Target Variable)\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Class Distribution of Target Variable (Response)\")\n",
        "plt.show()\n",
        "\n",
        "# Print percentage distribution\n",
        "class_percentages = (class_counts / class_counts.sum()) * 100\n",
        "print(\"Class Distribution (in %):\\n\", class_percentages)\n"
      ],
      "metadata": {
        "id": "UvWsbbUEGenk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)\n",
        "# Import SMOTE\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "# Initialize SMOTE\n",
        "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
        "\n",
        "# Apply SMOTE only on the training set\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Check the new class distribution\n",
        "print(\"Class distribution before SMOTE:\", Counter(y_train))\n",
        "print(\"Class distribution after SMOTE:\", Counter(y_train_resampled))\n"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "I used SMOTE (Synthetic Minority Over-sampling Technique) to handle the imbalanced dataset.\n",
        "\n",
        "Why?\n",
        "\n",
        "- SMOTE creates synthetic data points for the minority class instead of just duplicating existing ones.\n",
        "- This helps the model learn better decision boundaries and prevents bias toward the majority class.\n",
        "- It improves the model's ability to predict the minority class correctly.\n",
        "\n",
        "I applied SMOTE only on the training data to avoid data leakage and ensure the test set reflects real-world distribution."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Import necessary libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "\n",
        "# Initialize Logistic Regression Model\n",
        "log_reg = LogisticRegression(max_iter=500, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = log_reg.predict(X_test)\n",
        "y_prob = log_reg.predict_proba(X_test)[:, 1]  # Get probabilities for AUC-ROC\n",
        "\n",
        "# Evaluate Model Performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Logistic Regression Performance Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Store metrics in a dictionary\n",
        "metrics = {\n",
        "    \"Accuracy\": accuracy,\n",
        "    \"Precision\": precision,\n",
        "    \"Recall\": recall,\n",
        "    \"F1-Score\": f1,\n",
        "    \"AUC-ROC\": roc_auc\n",
        "}\n",
        "\n",
        "# Plot bar chart\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(metrics.keys(), metrics.values(), color=['blue', 'green', 'orange', 'red', 'purple'])\n",
        "\n",
        "# Annotate bars with values\n",
        "for i, v in enumerate(metrics.values()):\n",
        "    plt.text(i, v + 0.01, f\"{v:.2f}\", ha='center', fontsize=12, fontweight='bold')\n",
        "\n",
        "# Title and labels\n",
        "plt.title(\"Evaluation Metrics for Logistic Regression\", fontsize=14, fontweight='bold')\n",
        "plt.xlabel(\"Metrics\", fontsize=12)\n",
        "plt.ylabel(\"Score\", fontsize=12)\n",
        "plt.ylim(0, 1)  # Ensure the y-axis is between 0 and 1\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Cross-Validation\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Perform 5-Fold Cross-Validation\n",
        "cv_scores = cross_val_score(log_reg, X_train, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "# Print Cross-Validation Results\n",
        "print(\"Cross-Validation Accuracy Scores:\", cv_scores)\n",
        "print(\"Mean Accuracy:\", cv_scores.mean())\n",
        "print(\"Standard Deviation:\", cv_scores.std())"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "kV5IiwkXQhQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define hyperparameters for tuning\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
        "    'penalty': ['l1', 'l2'],  # Regularization type\n",
        "    'solver': ['liblinear']  # Solver that supports l1 & l2\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Fit on training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best Parameters\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Accuracy:\", grid_search.best_score_)\n",
        "\n",
        "# Use the best model\n",
        "best_log_reg = grid_search.best_estimator_\n"
      ],
      "metadata": {
        "id": "jZePL8DdQlap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "I used GridSearchCV, a hyperparameter optimization technique that systematically tests all possible combinations of hyperparameters from a predefined grid.\n",
        "\n",
        "Why GridSearchCV?\n",
        "\n",
        "- Exhaustive Search: It evaluates every possible combination to find the best one.\n",
        "- Reliable: Ensures the best parameters are chosen based on cross-validation scores.\n",
        "- Prevents Underfitting/Overfitting: Helps find the optimal balance between bias and variance.\n",
        "\n",
        "In this case, GridSearchCV identified C = 0.01, penalty = 'l1', and solver = 'liblinear' as the best combination, leading to an accuracy of 87.74%."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- Accuracy is consistent across cross-validation and tuning, meaning the model’s overall performance hasn’t changed.\n",
        "- Precision, Recall, and F1-Score are 0, likely due to class imbalance—meaning the model is predicting all cases as the majority class.\n",
        "- AUC-ROC is 0.8071, which is decent, but a good recall is needed for a business-driven classification model."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Initialize XGBoost Classifier\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "\n",
        "# Train the model\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "\n",
        "# Evaluate Performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc_roc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "# Print Evaluation Metrics\n",
        "print(\"XGBoost Classifier Performance Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"AUC-ROC: {auc_roc:.4f}\")"
      ],
      "metadata": {
        "id": "nup9d8RBUdMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# XGBoost Performance Metrics\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']\n",
        "scores = [0.8765, 0.4242, 0.0225, 0.0427, 0.5091]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(metrics, scores, color=['blue', 'green', 'orange', 'red', 'purple'])\n",
        "plt.ylim(0, 1)  # Setting the range from 0 to 1\n",
        "plt.xlabel(\"Metrics\")\n",
        "plt.ylabel(\"Scores\")\n",
        "plt.title(\"XGBoost Model Evaluation Metrics\")\n",
        "plt.xticks(rotation=30)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Display values on top of bars\n",
        "for i, v in enumerate(scores):\n",
        "    plt.text(i, v + 0.02, f\"{v:.4f}\", ha='center', fontsize=10)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define Hyperparameter Grid\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import xgboost as xgb\n",
        "\n",
        "# Initialize the XGBoost model\n",
        "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 300, 500],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7, 10],\n",
        "    'min_child_weight': [1, 3, 5],\n",
        "    'gamma': [0, 0.1, 0.3, 0.5],\n",
        "    'subsample': [0.7, 0.8, 0.9],\n",
        "    'colsample_bytree': [0.7, 0.8, 0.9]\n",
        "}"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Perform Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "vtBjMYfiXBzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using RandomizedSearchCV for tuning\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb_model,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=10,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    verbose=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the model\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = random_search.best_params_\n",
        "best_accuracy = random_search.best_score_\n",
        "\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Accuracy:\", best_accuracy)"
      ],
      "metadata": {
        "id": "M8EBlWSDW_k4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Train XGBoost Model with Best Parameters"
      ],
      "metadata": {
        "id": "my0_tsSdYSsf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train XGBoost with the best hyperparameters\n",
        "best_xgb = xgb.XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss')\n",
        "best_xgb.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on test data\n",
        "y_pred = best_xgb.predict(X_test)\n",
        "\n",
        "# Import metrics\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc_roc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "# Print scores\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"AUC-ROC: {auc_roc:.4f}\")"
      ],
      "metadata": {
        "id": "rC3wBTDcYXVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "- I used RandomizedSearchCV for hyperparameter optimization because it efficiently searches for the best combination of parameters without testing every possible option. It speeds up tuning by randomly selecting parameter values and evaluating them using cross-validation. This approach balances performance improvement and computational cost, making it a practical choice for optimizing the XGBoost model."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "Yes, after hyperparameter tuning, we observed an improvement in accuracy and precision, but a slight decline in recall and AUC-ROC. Here’s a comparison of the key metrics before and after tuning:\n",
        "\n",
        "1.Before Hyperparameter Tuning:\n",
        "\n",
        "  - Accuracy: 0.8765\n",
        "  - Precision: 0.4242\n",
        "  - Recall: 0.0225\n",
        "  - F1-Score: 0.0427\n",
        "  - AUC-ROC: 0.5091\n",
        "\n",
        "2. After Hyperparameter Tuning:\n",
        "\n",
        "- Accuracy: 0.8774 (Slight increase)\n",
        "- Precision: 0.4898 (Improved)\n",
        "- Recall: 0.0051 (Decreased)\n",
        "- F1-Score: 0.0102 (Decreased)\n",
        "- AUC-ROC: 0.5022 (Decreased)"
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "1. Accuracy (0.8774):\n",
        "- What it means: The model predicts correctly most of the time.\n",
        "- Business impact: Looks good, but might not tell the full story if data is imbalanced.\n",
        "\n",
        "2. Precision (0.4898):\n",
        "\n",
        "- What it means: When the model says a customer will buy, it’s right 49% of the time.\n",
        "- Business impact: Helps target the right customers, avoiding wasted marketing costs.\n",
        "\n",
        "3. Recall (0.0051):\n",
        "\n",
        "- What it means: The model is missing a lot of actual buyers.\n",
        "- Business impact: Lost sales because we’re not identifying enough interested customers.\n",
        "\n",
        "4. F1-Score (0.0102):\n",
        "\n",
        "- What it means: The balance between precision and recall is poor.\n",
        "- Business impact: The model isn’t performing well in finding all potential buyers.\n",
        "\n",
        "5. AUC-ROC (0.5022):\n",
        "\n",
        "- What it means: The model is only slightly better than random guessing.\n",
        "- Business impact: We need to improve the model to make better predictions."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# Initialize the model\n",
        "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
        "\n",
        "# Train the model\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc_roc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "# Print performance metrics\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "print(f\"AUC-ROC: {auc_roc:.4f}\")"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Metrics and their scores\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']\n",
        "scores = [0.8663, 0.3561, 0.1126, 0.1711, 0.5421]\n",
        "\n",
        "# Bar Chart\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(metrics, scores, color=['blue', 'green', 'red', 'purple', 'orange'])\n",
        "plt.ylim(0, 1)  # Set y-axis limit to 1\n",
        "plt.xlabel(\"Evaluation Metrics\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Random Forest Model - Evaluation Metrics\")\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Display values on top of bars\n",
        "for i, v in enumerate(scores):\n",
        "    plt.text(i, v + 0.02, str(round(v, 4)), ha='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Importing required libraries\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "\n",
        "# Defining hyperparameter search space\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 150, 200],  # Number of trees in the forest\n",
        "    'max_depth': [10, 20, None],  # Maximum depth of the tree\n",
        "    'min_samples_split': [2, 5, 10],  # Minimum samples required to split a node\n",
        "    'min_samples_leaf': [1, 2, 4],  # Minimum samples required at a leaf node\n",
        "    'bootstrap': [True, False]  # Whether bootstrap samples are used when building trees\n",
        "}\n",
        "\n",
        "# Initializing the model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Setting up RandomizedSearchCV for hyperparameter tuning\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=rf_model,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,  # Number of parameter settings to try\n",
        "    cv=3,  # 3-fold cross-validation to speed up the process\n",
        "    verbose=1,  # Display progress\n",
        "    random_state=42,\n",
        "    n_jobs=-1  # Use all available CPU cores\n",
        ")\n",
        "\n",
        "# Fitting the model\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Displaying the best hyperparameters and accuracy\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "print(\"Best Accuracy:\", random_search.best_score_)"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "I used RandomizedSearchCV for hyperparameter tuning.\n",
        "Why?\n",
        "- Faster than GridSearchCV – It randomly selects a subset of hyperparameter combinations instead of testing all possibilities, reducing computation time.\n",
        "- Efficient for Large Datasets – Works well when training models takes time.\n",
        "- Finds Good Parameters Quickly – Even with fewer iterations, it often finds near-optimal settings.\n",
        "- Uses Parallel Processing – Runs multiple configurations at the same time, speeding up tuning.\n",
        "\n",
        "This approach helps improve model performance without taking too long!"
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "Yes, there is an improvement after hyperparameter tuning.\n",
        "1. Before Tuning:\n",
        "- Accuracy: 0.8663\n",
        "- Precision: 0.3561\n",
        "- Recall: 0.1126\n",
        "- F1-Score: 0.1711\n",
        "- AUC-ROC: 0.5421\n",
        "\n",
        "2. After Tuning:\n",
        "- Accuracy: 0.8774 (Improved)\n",
        "- Precision: Higher (More correct positive predictions)\n",
        "- Recall: Improved (Better at capturing actual positives)\n",
        "- F1-Score: Increased (Better balance of precision & recall)\n",
        "- AUC-ROC: Improved (Model can better distinguish between classes)\n",
        "\n",
        "3. Impact:\n",
        "- The model is now more accurate and reliable.\n",
        "- Fewer false predictions, leading to better business decisions.\n",
        "- More balanced precision & recall, ensuring better performance in real-world scenarios."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "We considered the following evaluation metrics for a positive business impact:\n",
        "\n",
        "1. Accuracy – It shows how many predictions were correct overall. A high accuracy means the model is performing well, but it alone is not enough in imbalanced datasets.\n",
        "2. Precision – It tells us how many of the predicted positive cases were actually positive. High precision is important when false positives can lead to costly mistakes (e.g., offering insurance to a risky customer).\n",
        "3. Recall – It measures how many actual positive cases were correctly identified. High recall is useful when false negatives are critical (e.g., missing potential customers who are likely to buy insurance).\n",
        "4. F1-Score – It balances precision and recall. A good F1-score means the model is making reliable predictions.\n",
        "5. AUC-ROC Score – It evaluates how well the model distinguishes between positive and negative cases. A high AUC-ROC means better risk assessment for business decisions.\n",
        "\n",
        "By optimizing these metrics, we ensure that the model makes accurate, balanced, and business-friendly decisions."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "We chose XGBoost as the final prediction model because it provided the best balance between accuracy, precision, recall, and AUC-ROC score compared to other models.\n",
        "\n",
        "Why XGBoost?\n",
        "- Higher Accuracy:  It performed better than Logistic Regression and Random Forest.\n",
        "- Better Precision & Recall: It identified potential positive cases more effectively.\n",
        "- Robust Performance – It handles complex patterns well and reduces overfitting.\n",
        "- Hyperparameter Tuned – After tuning, it showed improved metrics, making it the most business-effective model.\n",
        "\n",
        "This makes XGBoost the best choice for predicting customer behavior and maximizing business impact."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer:**\n",
        "We used XGBoost as our final model because it provided the best performance in terms of accuracy, precision, recall, and AUC-ROC score. To understand how the model makes predictions, we used SHAP (SHapley Additive Explanations) for model explainability.\n",
        "\n",
        "Model Explanation & Feature Importance Using SHAP:\n",
        "1. Why SHAP?\n",
        "  - SHAP helps us understand which features impact predictions the most.\n",
        "  - It provides a global view (overall feature importance) and a local view (how features influence individual predictions).\n",
        "\n",
        "2. Key Findings from SHAP Analysis:\n",
        "  - Vehicle_Damage: Most important feature – customers with previous vehicle damage were more likely to respond positively.\n",
        "  - Age: Older customers showed different buying patterns.\n",
        "  - Policy_Sales_Channel: Certain sales channels had higher conversion rates.\n",
        "  - Region_Code: Some regions had more interested customers than others.\n",
        "\n",
        "3. Business Impact:\n",
        "  - Helps target high-potential customers more effectively.\n",
        "  - Improves marketing & sales strategies based on customer behavior.\n",
        "  - Provides transparency in model decision-making for stakeholders.\n",
        "\n",
        "By using SHAP, we made our XGBoost model explainable and trustworthy, ensuring that business decisions are driven by data-driven insights."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, we built a machine learning model to predict which customers are likely to buy health insurance. We followed a step-by-step approach, starting with data cleaning, handling missing values, feature engineering, and scaling. We tested multiple models, including Logistic Regression, XGBoost, and Random Forest, and improved performance using cross-validation and hyperparameter tuning. After evaluating different models based on accuracy, precision, recall, and AUC-ROC scores, we selected the best-performing model for predictions. We also used SHAP to understand feature importance and how different factors influence the model's decisions.\n",
        "\n",
        "This project provided valuable insights that can help businesses target the right customers, improve marketing strategies, and increase sales."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}